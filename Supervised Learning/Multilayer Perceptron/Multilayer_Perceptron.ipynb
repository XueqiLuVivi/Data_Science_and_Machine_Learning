{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "The Multilayer Perceptron was developed to tackle this limitation. It is a neural network where the mapping between inputs and output is non-linear.\n",
    "\n",
    "A Multilayer Perceptron has input and output layers, and one or more hidden layers with many neurons stacked together. And while in the Perceptron the neuron must have an activation function that imposes a threshold, like ReLU or sigmoid, neurons in a Multilayer Perceptron can use any arbitrary activation function.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"MP1.png\" width=\"700\">\n",
    "</p>\n",
    "\n",
    "Multilayer Perceptron falls under the category of feedforward algorithms, because inputs are combined with the initial weights in a weighted sum and subjected to the activation function, just like in the Perceptron. But the difference is that each linear combination is propagated to the next layer.\n",
    "\n",
    "Each layer is feeding the next one with the result of their computation, their internal representation of the data. This goes all the way through the hidden layers to the output layer.\n",
    "\n",
    "If the algorithm only computed the weighted sums in each neuron, propagated results to the output layer, and stopped there, it wouldn’t be able to learn the weights that minimize the cost function. If the algorithm only computed one iteration, there would be no actual learning.\n",
    "\n",
    "This is where Backpropagation comes into play.\n",
    "\n",
    "Backpropagation is the learning mechanism that allows the Multilayer Perceptron to iteratively adjust the weights in the network, with the goal of minimizing the cost function.\n",
    "\n",
    "There is one hard requirement for backpropagation to work properly. The function that combines inputs and weights in a neuron, for instance the weighted sum, and the threshold function, for instance ReLU, must be differentiable. These functions must have a bounded derivative, because Gradient Descent is typically the optimization function used in MultiLayer Perceptron.\n",
    "\n",
    "In each iteration, after the weighted sums are forwarded through all layers, the gradient of the Mean Squared Error is computed across all input and output pairs. Then, to propagate it back, the weights of the first hidden layer are updated with the value of the gradient. That’s how the weights are propagated back to the starting point of the neural network.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"MP2.png\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "This process keeps going until gradient for each input-output pair has converged, meaning the newly computed gradient hasn’t changed more than a specified convergence threshold, compared to the previous iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "In this project I will use fashion mnist data from tensorflow.keras.datasets to presiction the imange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 18:40:28.724354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(train_X) =(41999, 784)\n",
      "np.shape(test_X) = (18000, 784) \n",
      "\n",
      "np.shape(train_X[0]) = (784,)\n",
      "np.shape(test_X[0]) = (784,) \n",
      "\n",
      "train_X[0] = [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3   4   4   3   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18\n",
      " 108 125 125 109  20   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  31 183 212 213 190  45   8   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  21 172 233 253 245 114  32   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   4 115 204 253 250 127  37\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   2  84 174 252 250 129  39   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   2  84 174 252 251\n",
      " 159  69   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   4 114 204 253 251 159  69   1   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 129 217\n",
      " 254 249 127  38   0   0   0   0   0   0   0   4  21  32  37  37  37  37\n",
      "  18   0   0   0   0   0   0   9 140 222 253 245 114  32   0   0   0   0\n",
      "   0   4   9  34  82 114 127 127 127 125  63   2   0   0   0   0   0  32\n",
      " 203 245 251 222  52  10   0   7  20  38  50 115 139 204 233 245 250 250\n",
      " 250 245 125   4   0   0   0   0   0  37 215 249 251 222  52  11   4  34\n",
      "  77 127 140 204 220 245 252 254 254 254 254 250 127   4   0   0   0   0\n",
      "   0  37 217 250 254 246 134  78 116 177 220 249 250 254 254 254 254 254\n",
      " 254 254 250 241 113   4   0   0   0   0   0  39 217 250 254 252 191 159\n",
      " 204 234 247 254 254 254 254 254 252 250 249 245 220 202  77   2   0   0\n",
      "   0   0   2  82 233 252 254 254 252 251 254 254 254 254 251 233 222 215\n",
      " 172 140 125 114  50  34   7   0   0   0   0   0   4 114 245 254 255 254\n",
      " 254 254 254 254 252 245 232 172 140 125  82  51  37  32   9   4   0   0\n",
      "   0   0   0   0   4 127 250 254 254 254 251 246 222 204 172 115  82  22\n",
      "   9   4   2   0   0   0   0   0   0   0   0   0   0   0   4 113 241 249\n",
      " 249 243 175 128  51  32  21   4   2   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   2  77 201 215 215 202  95  47   9   4   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7\n",
      "  32  37  37  32   7   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   4   4   4   4   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"np.shape(train_X) ={np.shape(train_X)}\")\n",
    "print(f\"np.shape(test_X) = {np.shape(test_X)} \\n\")\n",
    "\n",
    "print(f\"np.shape(train_X[0]) = {np.shape(train_X[0])}\")\n",
    "print(f\"np.shape(test_X[0]) = {np.shape(test_X[0])} \\n\")\n",
    "\n",
    "print(f\"train_X[0] = {train_X[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the train_X is stores as 2 dimensional. Each image is comprised of a $28\\times 28$ grey scaled grid of pixel values. These values are floating point numbers in the interval $(0,1)$, where darker pixels will have values closer to $1$ and lighter pixels will have values closer to $0$. The following image represents one such example. \n",
    "\n",
    "We can view the image of one of these matrices by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y[0] = 7 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"{y_train[0] = } \\n\")\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(X_train[0], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding\n",
    "The following code scales our training and testing data, reshapes our images and stores them in new variable names, and one-hot encodes the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for x in X_train:\n",
    "  X.append(x.flatten().reshape(784, 1))\n",
    "\n",
    "# Y will temp store one-hot encoded label vectors\n",
    "Y = []\n",
    "for y in y_train:\n",
    "  temp_vec = np.zeros((10, 1))\n",
    "  temp_vec[y][0] = 1.0\n",
    "  Y.append(temp_vec)\n",
    "\n",
    "# Our data will be stored as a list of tuples. \n",
    "train_data = [p for p in zip(X, Y)]\n",
    "\n",
    "\n",
    "p = train_data[0]\n",
    "print(p[1])\n",
    "print(y_train[0])\n",
    "\n",
    "X = []\n",
    "for x in X_test:\n",
    "  X.append(x.flatten().reshape(784, 1))\n",
    "\n",
    "Y = []\n",
    "for y in y_test:\n",
    "  temp_vec = np.zeros((10, 1))\n",
    "  temp_vec[y][0] = 1.0\n",
    "  Y.append(temp_vec)\n",
    "\n",
    "test_data = [p for p in zip(X, Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building the Network Architecture \n",
    "For our purposes, we will build a multilayered **fully connected**, or **dense**, neural network with $L$ layers, $784$ input notes, $L-2$ hidden layers of arbitrary size, and $10$ output nodes. \n",
    "\n",
    "\n",
    "For our activation function, we will use the sigmoid function:\n",
    "\n",
    "* Sigmoid Function\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}.\n",
    "$$\n",
    "\n",
    "For our cost function, we will use the Mean Sqaure Error cost:\n",
    "$$\n",
    "C(W, b) = \\frac{1}{2}\\sum_{k=1}^{10}(\\hat{y}^{(i)}_k - y^{(i)}_k)^2.\n",
    "$$\n",
    "\n",
    "Our goal will be to write a custom Python class implementing our desired structure. However, before doing so, we first sequentually write functions to better understand the process of programming the following:\n",
    "\n",
    "* Initializing the weights and biases of each layer\n",
    "* The feedforward phase\n",
    "* Calculation of the cost function\n",
    "* Calculation of the gradient\n",
    "* Iterating stochastic gradient descent\n",
    "\n",
    "First we will define our sigmoid activation function, its derivative, and the mean squared error for a single instance of training data. Do this by running the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "  return sigmoid(z)*(1.0-sigmoid(z))\n",
    "\n",
    "def mse(a, y):\n",
    "  return .5*sum((a[i]-y[i])**2 for i in range(10))[0]\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next we will write a custom function to initialize the weight matrices and bias column vectors for a dense neural network. Do this by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_weights(layers = [784, 60, 60, 10]):\n",
    "  W = [[0.0]]\n",
    "  B = [[0.0]]\n",
    "  for i in range(1, len(layers)):\n",
    "    w_temp = np.random.randn(layers[i], layers[i-1])*np.sqrt(2/layers[i-1])\n",
    "    b_temp = np.random.randn(layers[i], 1)*np.sqrt(2/layers[i-1])\n",
    "\n",
    "    W.append(w_temp)\n",
    "    B.append(b_temp)\n",
    "  return W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Phase\n",
    "\n",
    "For $\\ell = 1, \\dots, L$, each layer $\\ell$ in our network will have two phases, the preactivation phase $$\\mathbf{z}^{\\ell} = W^{\\ell}\\mathbf{a}^{\\ell-1} + \\mathbf{b}^{\\ell},$$ and postactivation phase $$\\mathbf{a}^{\\ell} = \\sigma(\\mathbf{z}^{\\ell}).$$ The preactivation phase consists of a weighted linear combination of postactivation values in the previous layer. The postactivation values consists of passing the preactivation value through an activation function elementwise. Note $\\mathbf{a}^0 = \\mathbf{x}^{(i)}$, where $\\mathbf{x}^{(i)}$ is the current input data into our network. \n",
    "\n",
    "We can test our activation functions and matrix dimensions by running the following code which manually implements the feedforward process on a neural network with the given dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(a0) = (784, 1) \n",
      "\n",
      "np.shape(W[1]) = (60, 784)\n",
      "np.shape(z1) = (60, 1)\n",
      "np.shape(a1) = (60, 1) \n",
      "\n",
      "np.shape(W[2]) = (60, 60)\n",
      "np.shape(z2) = (60, 1)\n",
      "np.shape(a2) = (60, 1) \n",
      "\n",
      "np.shape(W[3]) = (10, 60)\n",
      "np.shape(z3) = (10, 1)\n",
      "np.shape(a3) = (10, 1) \n",
      "\n",
      "Prediction: np.argmax(y_hat) = 7\n",
      "Target Label: np.argmax(yi) = 9\n",
      "mse(y_hat, yi) = 1.297954623355667\n"
     ]
    }
   ],
   "source": [
    "W, B = initialize_weights()\n",
    "\n",
    "x, y = train_data[0]\n",
    "a0 = x\n",
    "\n",
    "print(f\"np.shape(a0) = {np.shape(a0)} \\n\")\n",
    "\n",
    "z1 = W[1] @ a0 + B[1]\n",
    "a1 = sigmoid(z1)\n",
    "\n",
    "print(f\"np.shape(W[1]) = {np.shape(W[1])}\")\n",
    "print(f\"np.shape(z1) = {np.shape(z1)}\")\n",
    "print(f\"np.shape(a1) = {np.shape(a1)} \\n\")\n",
    "\n",
    "z2 = W[2] @ a1 + B[2]\n",
    "a2 = sigmoid(z2)\n",
    "\n",
    "print(f\"np.shape(W[2]) = {np.shape(W[2])}\")\n",
    "print(f\"np.shape(z2) = {np.shape(z2)}\")\n",
    "print(f\"np.shape(a2) = {np.shape(a2)} \\n\")\n",
    "\n",
    "z3 = W[3] @ a2 + B[3]\n",
    "a3 = sigmoid(z3)\n",
    "y_hat = a3\n",
    "print(f\"np.shape(W[3]) = {np.shape(W[3])}\")\n",
    "print(f\"np.shape(z3) = {np.shape(z3)}\")\n",
    "print(f\"np.shape(a3) = {np.shape(a3)} \\n\")\n",
    "\n",
    "\n",
    "print(f\"Prediction: np.argmax(y_hat) = {np.argmax(y_hat)}\")\n",
    "print(f\"Target Label: np.argmax(yi) = {np.argmax(y)}\")\n",
    "print(f\"mse(y_hat, yi) = {mse(y_hat, y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let define the  MultilayerPerceptron class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropogation Phase with Stochastic Gradient Descent \n",
    "We are now ready to define a custom Python ```DenseNetwork``` class which initializes the weights and bias for the network, and implements stochastic gradient descent shown below:\n",
    "\n",
    "1. For each $i = 1, \\dots, N$.\n",
    "2. Feedforward $\\mathbf{x}^{(i)}$ into the network. \n",
    "3. Compute $\\delta^{L} = \\nabla_aC\\otimes \\sigma'(\\mathbf{z}^{L})$.\n",
    "4. For $\\ell = L-1, \\dots, 1$, compute $\\delta^{\\ell} = \\big ( (\\mathbf{w}^{\\ell + 1})^{T} \\delta^{\\ell + 1} \\Big )\\otimes \\sigma'(\\mathbf{z}^{\\ell})$.\n",
    "5. For $\\ell = L, L-1, \\dots, 1$, \n",
    "\n",
    "$$\n",
    "w^{\\ell} \\leftarrow w^{\\ell} - \\alpha \\delta^{\\ell}(\\mathbf{a}^{\\ell-1})^{T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{\\ell} \\leftarrow b^{\\ell} - \\alpha \\delta^{\\ell}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = dict()\n",
    "delta_last = (A[-1] - y)*sigmoid_prime(Z[-1])\n",
    "deltas[L-1] = delta_last   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(L-2, 0, -1):\n",
    "  deltas[l] = (W[l+1].T @ deltas[l+1])*sigmoid_prime(Z[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.04\n",
    "for i in range(1, 4):\n",
    "  W[i] = W[i] - alpha*deltas[i]@A[i-1].T\n",
    "  B[i] = B[i] - alpha*deltas[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(W, B, p, predict_vector = False):\n",
    "  Z =[[0.0]]\n",
    "  A = [p[0]]\n",
    "  L = len(W)\n",
    "  for i in range(1, L):\n",
    "    z = (W[i] @ A[i-1]) + B[i]\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    Z.append(z)\n",
    "    A.append(a)\n",
    "\n",
    "  if predict_vector == True:\n",
    "    return A[-1]\n",
    "  else:\n",
    "    return Z, A\n",
    "\n",
    "def deltas_dict(W, B, p):\n",
    "  Z, A = forward_pass(W, B, p)\n",
    "  L = len(W)\n",
    "  deltas = dict()\n",
    "  deltas[L-1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
    "  for l in range(L-2, 0, -1):\n",
    "    deltas[l] = (W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
    "\n",
    "  return A, deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(W, B, data):\n",
    "  c = 0.0\n",
    "  for p in data:\n",
    "    a = forward_pass(W, B, p, predict_vector=True)\n",
    "    c += mse(a, p[1])\n",
    "  return c/len(data)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jq/dmk6wkk55k500yv3vtcrjs0m0000gn/T/ipykernel_10209/4285135567.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 1.3435707021617738\n"
     ]
    }
   ],
   "source": [
    "W, B = initialize_weights()\n",
    "print(f\"Initial Cost = {MSE(W, B, train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value = 6\n",
      "Actual Value = 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0, len(X_test))\n",
    "prediction = np.argmax(forward_pass(W, B, test_data[i], predict_vector=True))\n",
    "print(f\"Predicted Value = {prediction}\")\n",
    "print(f\"Actual Value = {y_test[i]}\")\n",
    "plt.imshow(X_test[i], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNetwork(W, B, data, alpha = 0.04, epochs = 3):\n",
    "  L = len(W)\n",
    "  print(f\"Initial Cost = {MSE(W, B, data)}\")\n",
    "  for k in range(epochs):\n",
    "    for p in data:\n",
    "      A, deltas = deltas_dict(W, B, p)\n",
    "      for i in range(1, L):\n",
    "        W[i] = W[i] - alpha*deltas[i]@A[i-1].T\n",
    "        B[i] = B[i] - alpha*deltas[i]\n",
    "    print(f\"{k} Cost = {MSE(W, B, data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
